Q-Sentinel Training

YOLOv8 Training Pipeline for Industrial PU Inspection

Q-Sentinel TrainingModels is a dedicated repository for training, validating, and evaluating YOLOv8 object detection models used by the Q-Sentinel AI Vision System.

This project focuses on industrial-quality dataset handling, robust evaluation, and production-oriented metrics (OK/NOK decision logic), not just raw mAP scores.

ğŸ¯ Project Goal

Train a YOLOv8 model to inspect camera brackets with PU application and detect:

PU correctly applied (OK)

PU missing / incorrect (NOK)

The trained model is later loaded into the Q-Sentinel runtime application for real production use.

ğŸ§  Key Features

âœ” YOLOv8 training (CPU-safe)
âœ” Support for 6-class setup (PU1/PU2/PU3 â€“ OK & NOK)
âœ” Dataset validation & sanity checks
âœ” Controlled NOK data augmentation (bbox-safe)
âœ” Training loss & metric plots
âœ” Piece-level OK/NOK accuracy evaluation
âœ” Production-oriented metrics (Recall, False Rejects, Miss Rate)

ğŸ“ Repository Structure
Q-Sentinel-TrainingModels/
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ pu_dataset.yaml        # YOLO dataset configuration
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ train_yolo.py          # Model training
â”‚   â”œâ”€â”€ plot_results.py        # Loss & metric graphs
â”‚   â”œâ”€â”€ eval_piece_accuracy_6cls.py  # OK/NOK accuracy per piece
â”‚   â”œâ”€â”€ dataset_check.py       # Dataset validation
â”œâ”€â”€ tools/
â”‚   â””â”€â”€ augment_nok_yolo.py    # Controlled NOK augmentation
â”œâ”€â”€ runs/                      # YOLO training outputs (auto-generated)
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

ğŸ—‚ Dataset Structure (YOLO format)

Dataset path used in this project:

C:/Users/yonut/PycharmProjects/Dataset


Required structure:

Dataset/
â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ train/
â”‚   â””â”€â”€ val/
â””â”€â”€ labels/
    â”œâ”€â”€ train/
    â””â”€â”€ val/


Each image must have a corresponding .txt label file with the same filename.

ğŸ· Class Mapping (6-Class Setup)
0: PU1_OK
1: PU2_OK
2: PU3_OK
3: PU1_NOK
4: PU2_NOK
5: PU3_NOK


ğŸ“Œ Each image contains 3 bounding boxes (PU1, PU2, PU3).
ğŸ“Œ A part is considered NOK if any PUx_NOK is present.

ğŸ§ª Dataset Validation

Before training, always run:

python scripts/dataset_check.py


This checks:

missing labels

invalid class IDs

class distribution

train / val balance

ğŸ” Controlled Data Augmentation (NOK Only)

If real NOK samples are limited, use controlled augmentation:

python tools/augment_nok_yolo.py


âœ” Augments only NOK images
âœ” Preserves bounding box correctness
âœ” Applies safe transformations (brightness, blur, noise, small rotation)
âŒ No flips or unsafe geometry changes

ğŸš€ Training the Model
python scripts/train_yolo.py


Recommended parameters (CPU):

Model: yolov8n.pt

Epochs: 50

Batch size: 8

Image size: 640

Training artifacts are saved automatically to:

runs/detect/train/
â”œâ”€â”€ weights/best.pt
â”œâ”€â”€ results.csv
â””â”€â”€ results.png

ğŸ“Š Visualizing Training Results

Generate custom graphs:

python scripts/plot_results.py


Outputs:

custom_loss.png

custom_metrics.png

ğŸ§  Evaluating Industrial Performance (OK / NOK)

YOLO mAP alone is not enough for production.
Evaluate piece-level accuracy:

python scripts/eval_piece_accuracy_6cls.py


Reported metrics:

Accuracy (OK/NOK)

Precision

Recall

False Reject Rate (OK â†’ NOK)

Miss Rate (NOK â†’ OK)

These metrics directly reflect factory performance.

ğŸ”— Integration

The resulting model (best.pt) is loaded into the Q-Sentinel runtime application for:

live camera inspection

image upload testing

operator confirmation workflow

production statistics & reporting

Training and runtime are intentionally separated.

âš ï¸ Notes & Best Practices

Do not train on Python 3.12 (use 3.9â€“3.10)

Avoid copying images without real augmentation

Keep validation set untouched

Prioritize Recall on NOK over raw mAP

ğŸ­ Production Philosophy

A model with slightly lower mAP but high NOK recall
is far safer than a â€œperfectâ€ mAP model that misses defects.

This repository is built with industrial reliability in mind.

ğŸ“Œ License

Internal / R&D use.
Adapt freely for industrial vision projects.